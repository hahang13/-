import csv
import nltk
from nltk.tokenize import word_tokenize
from collections import Counter
from nltk.corpus import stopwords
import pandas as pd
import csv
from nltk.tokenize import word_tokenize
from collections import Counter
from nltk.corpus import stopwords
# 불용어 추가
additional_stopwords = ['``', '...', ',', '/', '.', '[', ']', "'", "''", '’', '‘', '(', ')', '“', '”', '?','%']
stop_list = stopwords.words('english') + additional_stopwords

# CSV 파일 열기
with open('D:/big16/final-dev/final_prac/하현수/뉴스 데이터/뉴스 크롤링/관련주 크롤링/루닛.csv', 'r', encoding='UTF-8') as file:
    reader = csv.reader(file)

    header = next(reader)

    text_column_index = 1
    
    # 데이터 토큰화
    tokens = []
    for row in reader:
        text = row[text_column_index]
        text_tokens = word_tokenize(text)
        
        # 단어 정규화 및 불용어 필터링
        filtered_tokens = [word.replace("'루닛", "루닛") for word in text_tokens if word.lower() not in stop_list]
        
        tokens.extend(filtered_tokens)
        
    # 빈도수 계산
    word_freq = Counter(tokens)

df = pd.DataFrame(list(word_freq.items()), columns=['단어', '빈도수'])
df_sorted = df.sort_values(by='빈도수', ascending=False)

top_15_words = df_sorted.head(15)
top_15_words
